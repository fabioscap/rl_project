{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39588,"status":"ok","timestamp":1671765644527,"user":{"displayName":"mattia castelmare","userId":"03295257409724725105"},"user_tz":-60},"id":"ayf_kMXl-vKo","outputId":"72f1ec61-6a2c-4565-f059-48910a3572d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive/\")\n"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":17892,"status":"ok","timestamp":1671766448831,"user":{"displayName":"mattia castelmare","userId":"03295257409724725105"},"user_tz":-60},"id":"s4Umdut1_6kZ"},"outputs":[],"source":["!pip install dm_control --quiet\n","!pip install imageio_ffmpeg --quiet\n","!pip install git+https://github.com/denisyarats/dmc2gym.git --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":361,"status":"ok","timestamp":1671766451901,"user":{"displayName":"mattia castelmare","userId":"03295257409724725105"},"user_tz":-60},"id":"nUKMlO7xVZp3","outputId":"ce911e7c-64fb-49f3-adda-4e655f073dd9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/RL/Project_CURL1\n","env: MUJOCO_GL=egl\n","env: GIT_DISCOVERY_ACROSS_FILESYSTEM=true\n"]}],"source":["%cd /content/drive/MyDrive/RL/Project_CURL1\n","%env MUJOCO_GL=egl\n","%env GIT_DISCOVERY_ACROSS_FILESYSTEM=true"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIyxMmc_SKeE"},"outputs":[],"source":["import numpy as np\n","import torch\n","import os\n","import time\n","from dm_control import suite\n","import dmc2gym\n","import utils\n","from logger import Logger\n","from video import VideoRecorder\n","\n","from agent import Agent\n","\n","\n","\n","seed = 1815675\n","domain_name = 'ball_in_cup'\n","task_name = 'catch'\n","image_size = 100\n","image_cropped_size = 84\n","frame_stack = 3\n","frame_skip = 2\n","work_dir = '/content/drive/MyDrive/RL/Project_CURL1'\n","save_video = True\n","\n","replay_buffer_capacity = 100000\n","batch_size = 512\n","\n","s_dim = 50\n","a_dim = 2\n","\n","num_train_steps = 1000000\n","max_episode_steps = 1000\n","\n","init_steps = 1000\n","\n","save_model = True\n","save_buffer = False\n","\n","num_eval_episodes = 5\n","eval_frequency = 1000\n","\n","def evaluate(env, agent, video, num_episodes, L, step):\n","    for i in range(num_episodes):\n","        obs = env.reset()\n","\n","        video.init(enabled=(i == 0))\n","        done = False\n","        episode_reward = 0\n","        while not done: \n","            with utils.eval_mode(agent):\n","                action = agent.select_action(obs)\n","                action = action.astype(np.float32)\n","\n","            obs, reward, done, _ = env.step(action)\n","            video.record(env)\n","            episode_reward += reward\n","\n","\n","        video.save('%d.mp4' % step)\n","        L.log('eval/episode_reward', episode_reward, step)\n","    L.dump(step)\n","\n","def main():\n","    utils.set_seed_everywhere(seed)\n","\n","    env = dmc2gym.make(\n","        domain_name=domain_name,\n","        task_name=task_name,\n","        seed=seed,\n","        visualize_reward=False,\n","        from_pixels=True,\n","        height=image_size,\n","        width=image_size,\n","        frame_skip=frame_skip\n","    )\n","\n","    observation_shape = env.observation_space.shape\n","    observation_cropped_shape = (observation_shape[0],) + (image_cropped_size, image_cropped_size)\n","\n","    action_shape = env.action_space.shape \n","\n","    utils.make_dir(work_dir)\n","    video_dir = utils.make_dir(os.path.join(work_dir, 'video'))\n","    model_dir = utils.make_dir(os.path.join(work_dir, 'model'))\n","    buffer_dir = utils.make_dir(os.path.join(work_dir, 'buffer'))\n","\n","    video = VideoRecorder(video_dir if save_video else None)\n","\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    replay_buffer = utils.ReplayBuffer(\n","        obs_shape=observation_shape,\n","        action_shape=action_shape,\n","        capacity=replay_buffer_capacity,\n","        batch_size=batch_size,\n","        device=device\n","    )\n","\n","    agent = Agent(\n","        obs_cropped_shape=observation_cropped_shape,\n","        a_shape=action_shape,\n","        s_dim = s_dim,\n","        a_dim = a_dim,\n","        device=device\n","    )\n","\n","    L = Logger(work_dir, use_tb=False)\n","    \n","    episode, episode_reward, done = 0, 0, True\n","    start_time = time.time()\n","    for step in range(num_train_steps): \n","        if done:\n","            if step > 0:\n","                L.log('train/duration', time.time() - start_time, step)\n","                start_time = time.time()\n","                L.dump(step)\n","\n","            # evaluate agent periodically\n","            if step > 0 and step % eval_frequency == 0:\n","                L.log('eval/episode', episode, step)\n","                evaluate(env, agent, video, num_eval_episodes, L, step)\n","                if save_model:\n","                    pass # agent.save(model_dir, step)\n","                if save_buffer:\n","                    replay_buffer.save(buffer_dir)\n","\n","            L.log('train/episode_reward', episode_reward, step)\n","            \n","            \n","            obs = env.reset()\n","            done = False\n","            episode_reward = 0\n","            episode_step = 0\n","            episode += 1\n","            L.log('train/episode', episode, step)\n","\n","        # sample action for data collection\n","        if step < init_steps:\n","            action = env.action_space.sample()\n","        else:\n","            with utils.eval_mode(agent):\n","                action = agent.sample_action(obs)\n","\n","        # run training update\n","        if step >= init_steps:\n","            num_updates = 1 \n","            for _ in range(num_updates):\n","                lc, la, lcont = agent.update(replay_buffer, step, L)\n","                L.log(\"train/critic_loss\", lc, step)\n","                L.log(\"train/actor_loss\", la, step)\n","                L.log(\"train/ae_loss\", lcont, step)\n","\n","        next_obs, reward, done, _ = env.step(action)\n","        done = episode_step + 1 == max_episode_steps\n","\n","        # allow infinit bootstrap\n","        done_bool = 0 if episode_step + 1 == max_episode_steps else float(\n","            done\n","        )\n","        episode_reward += reward\n","        replay_buffer.add(obs, action, reward, next_obs, done_bool)\n","\n","        obs = next_obs\n","        episode_step += 1\n","\n","\n","      \n","if __name__ == '__main__':\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyOKWEIY11QpCo3BigqXm6qP"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}